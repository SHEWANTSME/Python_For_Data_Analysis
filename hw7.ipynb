{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160dabd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"Are You in the House Alone?\" belongs to the pre-cable TV days when the networks were eager to offer an alternative to popular TV shows. It is well-made thriller with a talented cast and credible situations. Kathleen Beller plays a High School student who gets a series of threatening letters. Everyone seems to think that it is nothing more than a prank but Beller is really scared. Tony Bill and Blythe Danner play Beller\\'s parents, Ellen Travolta (John\\'s sister) is the High School Principal and Dennis Quaid has one of his earliest roles as a cocky rich kid. It\\'s a competent chiller with a still relevant social message. Beller is lovely - if you are 30 or older, you will remember that she was very popular among youngsters. Blythe Danner, who I usually don\\'t like, gives a truly moving performance. Nice little film.' \n",
      "\n",
      "b'\"Are You in the House Alone?\" belongs to the pre-cable TV days when the networks were eager to offer an alternative to popular TV shows. It is well-made thriller with a talented cast and credible situations. Kathleen Beller plays a High School student who gets a series of threatening letters. Everyone seems to think that it is nothing more than a prank but Beller is really scared. Tony Bill and Blythe Danner play Beller\\'s parents, Ellen Travolta (John\\'s sister) is the High School Principal and Dennis Quaid has one of his earliest roles as a cocky rich kid. It\\'s a competent chiller with a still relevant social message. Beller is lovely - if you are 30 or older, you will remember that she was very popular among youngsters. Blythe Danner, who I usually don\\'t like, gives a truly moving performance. Nice little film.'\n",
      "정답률 :  0.82\n"
     ]
    }
   ],
   "source": [
    "# 60175054 김준현\n",
    "from sklearn.datasets import load_files # data load를 위해\n",
    "from sklearn.feature_extraction.text import CountVectorizer # countvectorizer를 위해\n",
    "from sklearn.naive_bayes import MultinomialNB # naive_baysian을 사용하기 위해\n",
    "from sklearn import metrics # accuracy_score를 위해\n",
    "# 1-(a)\n",
    "reviews_train = load_files(\"/Users/qhdms/Downloads/Prac_BOW/aclImdb/train\") # train data가 있는 dir\n",
    "text_train , y_train = reviews_train.data , reviews_train.target # target -> label , data -> data\n",
    "\n",
    "reviews_test = load_files(\"/Users/qhdms/Downloads/Prac_BOW/aclImdb/test\") # test data가 있는 dir\n",
    "text_test , y_test = reviews_test.data , reviews_test.target \n",
    "\n",
    "# 1-(b)\n",
    "print(text_test[5],\"\\n\") # br 삭제전 일부 print\n",
    "text_test = [i.replace(b\"<br />\" , b\" \")for i in text_test] # br 삭제\n",
    "print(text_test[5]) # br 삭제 후 일부 print\n",
    "\n",
    "# 1-(c)\n",
    "vect = CountVectorizer(stop_words=\"english\").fit(text_train) # min_df는 default인 1로 설정했고 ( 별다른 말이 없으므로) 불용어는 english로 했다.\n",
    "feature_names = vect.get_feature_names()  # 특징(term) 추출해서 리스트 생성\n",
    "X_train = vect.transform(text_train) \n",
    "\n",
    "# 1-(d)\n",
    "X_test = vect.transform(text_test)\n",
    "nb = MultinomialNB() # using gaussian distribution\n",
    "nb.fit(X_train , y_train)  # fit and transform 과정이 필요하다.\n",
    "pre = nb.predict(X_test)\n",
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(\"정답률 : \" , round(ac_score, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2f662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass input=<function twitter_tokenizer_filter at 0x000001FEA259F4C0> as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 :  0.83\n",
      "  (0, 248358)\t0.6303222409610997\n",
      "  (0, 246232)\t0.26458844458802766\n",
      "  (0, 99567)\t0.5193460454404283\n",
      "  (0, 71119)\t0.5128026059076282\n",
      "  (1, 273335)\t0.39339783492704455\n",
      "  (1, 255126)\t0.48708202211988\n",
      "  (1, 190112)\t0.48708202211988\n",
      "  (1, 167602)\t0.4594654475140474\n",
      "  (1, 16352)\t0.39953955182265427\n",
      "  (2, 57394)\t1.0\n",
      "  (3, 271982)\t0.2350682561245384\n",
      "  (3, 234711)\t0.4553837778399886\n",
      "  (3, 222295)\t0.31086792096674587\n",
      "  (3, 208071)\t0.5291744229013852\n",
      "  (3, 177352)\t0.23027805651810662\n",
      "  (3, 145795)\t0.26087100319277146\n",
      "  (3, 33783)\t0.4895124432361123\n",
      "  (4, 283593)\t0.22305313413419903\n",
      "  (4, 261359)\t0.31594727615496576\n",
      "  (4, 210575)\t0.33021861268984737\n",
      "  (4, 207059)\t0.34154640977313266\n",
      "  (4, 185057)\t0.08755002116806476\n",
      "  (4, 181881)\t0.17559118145585131\n",
      "  (4, 150442)\t0.34154640977313266\n",
      "  (4, 133947)\t0.34154640977313266\n",
      "  :\t:\n",
      "  (149995, 105744)\t0.5709344001279767\n",
      "  (149995, 104438)\t0.4957716456131864\n",
      "  (149996, 272521)\t0.5257258012110156\n",
      "  (149996, 56643)\t0.3756327200947343\n",
      "  (149996, 54243)\t0.7632250268009211\n",
      "  (149997, 287413)\t0.42050487164943623\n",
      "  (149997, 279753)\t0.3827165387152868\n",
      "  (149997, 276532)\t0.39666308806341716\n",
      "  (149997, 251014)\t0.37741430673461246\n",
      "  (149997, 204171)\t0.1865650638237131\n",
      "  (149997, 105397)\t0.40655832230130584\n",
      "  (149997, 24486)\t0.42050487164943623\n",
      "  (149998, 256303)\t0.3350590014553481\n",
      "  (149998, 254425)\t0.3420275430303242\n",
      "  (149998, 217551)\t0.4014509525478402\n",
      "  (149998, 196356)\t0.4318159805164693\n",
      "  (149998, 186872)\t0.2316398172680169\n",
      "  (149998, 113562)\t0.4166334665321548\n",
      "  (149998, 52347)\t0.4425881456194418\n",
      "  (149999, 279282)\t0.3233082737223628\n",
      "  (149999, 257229)\t0.4488260315735005\n",
      "  (149999, 185057)\t0.2975899200959849\n",
      "  (149999, 146244)\t0.5804725540747906\n",
      "  (149999, 67785)\t0.4181939481104346\n",
      "  (149999, 55879)\t0.30599449130925677\n"
     ]
    }
   ],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Okt # for 형태소 분석\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 2-(a)\n",
    "df_train = pd.read_csv('/Users/qhdms/Downloads/ratings_train.txt' , delimiter = '\\t' , keep_default_na = False) \n",
    "df_test = pd.read_csv('/Users/qhdms/Downloads/ratings_test.txt' , delimiter = '\\t' , keep_default_na = False) \n",
    "txt_train = df_train['document']\n",
    "yy_train = df_train['label']\n",
    "txt_test = df_test['document']\n",
    "yy_test = df_test['label']# 1번처럼 해주면 된다. \n",
    "\n",
    "\n",
    "# 2-(d)-(b)\n",
    "twitter_tag = Okt()  # 형태소 분석기\n",
    "\n",
    "def twitter_tokenizer_filter(text):\n",
    "    malist = twitter_tag.pos(text,norm = True, stem = True) \n",
    "    r = [] \n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\" , \"Eomi\" , \"Punctuation\" , \"KoreanParticle\"]:\n",
    "            r.append(word[0])\n",
    "        return r\n",
    "vect = CountVectorizer(twitter_tokenizer_filter).fit(txt_train)\n",
    "XX_train = vect.transform(txt_train)\n",
    "clf_mult = MultinomialNB().fit(XX_train , yy_train)\n",
    "XX_test  = vect.transform(txt_test)\n",
    "\n",
    "# data prediction\n",
    "pre= clf_mult.predict(XX_test)\n",
    "ac_score = metrics.accuracy_score(yy_test, pre) \n",
    "print(\"정답률 : \" , round(ac_score,2))\n",
    "\n",
    "# 2-(c)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "x = TfidfVectorizer().fit(txt_train)\n",
    "xxx = x.transform(txt_train) \n",
    "#print(xxx.toarray()) -> 왜 안되는지 모르겠습니다.\n",
    "print(xxx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "befd6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " alpha 1.0 정답률 : 0.82578\n",
      " alpha 1.1 정답률 : 0.82578\n",
      " alpha 1.2000000000000002 정답률 : 0.82578\n",
      " alpha 1.3000000000000003 정답률 : 0.82578\n",
      " alpha 1.4000000000000004 정답률 : 0.82578\n",
      " alpha 1.5000000000000004 정답률 : 0.82578\n",
      " alpha 1.6000000000000005 정답률 : 0.82578\n",
      " alpha 1.7000000000000006 정답률 : 0.82578\n",
      " alpha 1.8000000000000007 정답률 : 0.82578\n",
      " alpha 1.9000000000000008 정답률 : 0.82578\n"
     ]
    }
   ],
   "source": [
    "# 2-(e)\n",
    "k = 1.0\n",
    "while(k<2.0):\n",
    "    nbb = MultinomialNB(alpha = k) # 1.8일때 가장 좋았었음\n",
    "    nbb.fit(XX_train , yy_train)\n",
    "    XX_test  = vect.transform(txt_test)\n",
    "    pre= clf_mult.predict(XX_test)\n",
    "    ac_score = metrics.accuracy_score(yy_test, pre) \n",
    "    print(f\" alpha {k} 정답률 : {ac_score}\")\n",
    "    k+=0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
